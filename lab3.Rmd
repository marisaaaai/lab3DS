---
title: "LAB3"
author: "Marisa Montoya, Majo Morales, Luis Garcia"
date: "8/16/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
setwd("C:/Users/Marisa Montoya}/lab3DS")
#setwd("C:/Users/LUIS PEDRO/Desktop/CNNDATA")
library(h2o)
library(keras)
library(tidyr)
library(ggplot2)
library(kernlab)
library(caret)
library(caTools)
library(gridExtra)
```
  
#Laboratorio 3 reconocimiento de caracteres en manuscritos

##Analisis Exploratorio

Los archivos de datos train.csv y test.csv contienen imágenes en escala de grises de dígitos dibujados a mano, del cero al nueve.Cada imagen tiene 28 píxeles de altura y 28 píxeles de ancho, para un total de 784 píxeles en total. Cada píxel tiene un único valor de píxel asociado, que indica la luminosidad u oscuridad de ese píxel, con números más altos que significan más oscuros. Este valor de píxel es un número entero entre 0 y 255, inclusive.El  conjunto  de  datos  de  entrenamiento,  (train.csv),  tiene  785  columnas.  La  primera  columna, llamada  "etiqueta",  es  el  dígito  dibujado  por  el  usuario.  El  resto  de  las  columnas  contienen  los valores decadapíxel dela imagen asociada.Cada columna de píxeles en el conjunto de entrenamiento tiene un nombre como pixelx, donde x es un número entero entre 0 y 783, inclusive. Para ubicar este píxel en la imagen, supongamos que hemos descompuesto x como x = i * 28 + j, donde i y j son números enteros entre 0 y 27, inclusive. Luego, pixelx se ubica en la fila iy la columna j de una matriz de 28 x 28, (indexando por cero)

```{r Analisis explor 1, echo=FALSE}
datos <- read.csv("./train.csv")
str(datos, list.len=ncol(datos))
summary(datos)
dim(datos)
datos$label[1:20]

```

De lo que podemos observar es que se cuenta con 785 columnas, siendo la primera en donde esta la etiqueta de que numero es la que se esta tratando mientras que las demas corresponden a los 784 pixeles de la imagen en total. Mientras que las columnas de pixeles su minimo es 0 y maximo es de 255, la columna de label va de 0 a 9. 

```{r echo=FALSE}
porcentaje<-0.8
set.seed(123)

corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train<-datos[corte,]
train <- cbind(train[,1],train[,-1]/255.0)


test<-datos[-corte,]
```

Dividimos el train y test del conjunto de datos y mostramos el head de train. 


```{r echo=FALSE}
head(train[1:10])

```

Al imprimir una imagen nos damos cuenta que necesita que sea rotada una vez a la derecha para que pueda ser observada de mejor manera. 

```{r echo=FALSE}
m = matrix(unlist(train[10,-1]),nrow = 28,byrow = T)
image(m,col=grey.colors(255))
```

Luego imprimimos seis imagenes con sus etiquetas para poder observarlas bien.

```{r echo=FALSE}
rotate <- function(x) t(apply(x, 2, rev)) #rota la imagen

par(mfrow=c(2,3))
lapply(1:6, 
    function(x) image(
                    rotate(matrix(unlist(train[x,-1]),nrow = 28,byrow = T)),
                    col=grey.colors(255),
                    xlab=train[x,1]
                )
)
par(mfrow=c(1,1)) # set plot options back to default

```


##h2o para la creacion de NN
   H2o es un paquete basado en una red neuronal artificial que es entrenada por un proceso estocastico usando back propagation. La red neuronal puede ser creada con varias capas escondidas. Para más conocimiento de la documentación consultar el siguiente link: https://docs.h2o.ai/h2o/latest-stable/h2o-docs/data-science/deep-learning.html 
  
  Se creo el modelo de h2o con los siguientes parametros:
  1. primero se creo el localh2o para tener una mayor eficiencia de tiempo.
  2. Se volvio la primera columna de train en factor para el uso del modelo
  3. se creo el train set con una funcion de h2o para que pueda ser aceptado por el modelo.
  4. Se instancio el modelo con parametros de 
    a. x las columnas usadas para la prediccion (2 a 785 porque 1 es la etiqueta), seran las variables predictoras donde esta la informacion de pixels
    b. y es en donde se encuentra la variable dependiente, en este caso 1.
    c. training_frame es nuestro dataset usado para la creacion del modelo.
    d. activation el cual espicifica la funcion de activacion que usara el modelo (si no se especifica es rectifier) en este caso usamos Rectifier with Dropout RELu, esto porque es una manera eficiente de usar el poder de la computadora.
    e. input_dropout_ratio lo que nos permite mejorar la generalizacion de la NN, 0.2 ya que es el sugerido por la documentacion
    f. hidden_dropout_ratio ya que especifica el radio de droput en las capas escondidad de la NN, aplicando el valor default de 0.5
    g. balance classes, se le da el valor de TRUE y se especifica cuantas capas escondidas se desea y de cuantos nodos seran.
    h. momentum_stable se coloco el valor sugerido por la documentacion 0.99
    i. nesterov_accelerated_gradient para que la computadora cree el modelo de manera rapida.
    j. epochs, se coloco 1 ya que mide las veces que se entrena el modelo para obtener el mejor valor posible.
```{r echo=FALSE}
localH2O = h2o.init(max_mem_size = '6g', # use 6GB of RAM
                    nthreads = -1) # use all CPUs 
```

```{r echo=FALSE}
#data as H2O
train[,1] = as.factor(train[,1]) # convert digit labels to factor for classification
train2 = as.h2o(train)

modelNN =
  h2o.deeplearning(x = 2:785,  
                   y = 1,   
                   training_frame = train2, 
                   activation = "RectifierWithDropout",
                   input_dropout_ratio = 0.2, 
                   hidden_dropout_ratios = c(0.5,0.5), 
                   balance_classes = TRUE, 
                   hidden = c(100,100),  
                   momentum_stable = 0.99,
                   nesterov_accelerated_gradient = T,
                   epochs = 1)

h2o.confusionMatrix(modelNN)


```

El modelo nos demuestra que luego de 1 epoch, el error es de 0.0888, lo cual se traduce a 1 - 0.0888 = 0.9112 de accuracy. En porcentaje es un accuracy del 91%, lo cual es buen porcentaje para una red neuronal simple. Sin embargo, le vamos a subir 4 epochs para observar si sube el accuracy.

```{r echo=FALSE}
modelNN =
  h2o.deeplearning(x = 2:785,  
                   y = 1,   
                   training_frame = train2, 
                   activation = "RectifierWithDropout",
                   input_dropout_ratio = 0.2, 
                   hidden_dropout_ratios = c(0.5,0.5), 
                   balance_classes = TRUE, 
                   hidden = c(100,100),  
                   momentum_stable = 0.99,
                   nesterov_accelerated_gradient = T,
                   epochs = 5)

h2o.confusionMatrix(modelNN)
```
Con 5 epoch vemos que bajo el error a 0.0591, lo que significa que subio el accuracy a 94% de valores correctos. Veremos si subimos a 10 epochs tmabien sube el accuracy
```{r echo=FALSE}
modelNN =
  h2o.deeplearning(x = 2:785,  
                   y = 1,   
                   training_frame = train2, 
                   activation = "RectifierWithDropout",
                   input_dropout_ratio = 0.2, 
                   hidden_dropout_ratios = c(0.5,0.5), 
                   balance_classes = TRUE, 
                   hidden = c(100,100),  
                   momentum_stable = 0.99,
                   nesterov_accelerated_gradient = T,
                   epochs = 10)

h2o.confusionMatrix(modelNN)
```
El error bajo nuevamente y el accuracy subio a ser de 95%, probaremos con 15 epochs.
```{r}
modelNN =
  h2o.deeplearning(x = 2:785,  
                   y = 1,   
                   training_frame = train2, 
                   activation = "RectifierWithDropout",
                   input_dropout_ratio = 0.2, 
                   hidden_dropout_ratios = c(0.5,0.5), 
                   balance_classes = TRUE, 
                   hidden = c(100,100),  
                   momentum_stable = 0.99,
                   nesterov_accelerated_gradient = T,
                   epochs = 15)

h2o.confusionMatrix(modelNN)
```

El accuracy subio un 1% por lo que nos quedaremos con 15 epochs realizados, un error del 3.92% y un accuracy del 96.08% para este modelo. 

##Formacion de modelo con SVM 

Se carga la data:
```{r Data, echo = FALSE}
datos <- read.csv("train.csv")

View(datos) # Data has no column names

names(datos)[1] <- "label"

```

Se limpian los datos para no tener datos innecesarios:
```{r Clean data, echo = FALSE}
# headers and footers

head(datos, 1) # no unnecessary headers
View(datos)

tail(datos, 1) # no unnecessary footers

# Duplicated rows

sum(duplicated(datos)) # no duplicate rows

# Checking for NAs
sum(sapply(datos, function(x) sum(is.na(x)))) # There are no missing values

```

Al limpiar los datos se puede ver que no hay datos duplicados y tenemos titulos en ambos data sets. 
```{r Entender data, echo = FALSE}
str(datos) # all dependant variables integers, 10000 observations, 785 variables

summary(datos[ , 2:100]) # but some only go up to ~100, data needs to be scaled

```

Se generan subsets del conjunto de datos para que sean manejables y poder tener el dataset train y test. 
```{r Preparacion data, echo =FALSE}
datos$label <- factor(datos$label)
summary(datos$label)

dim(datos) 
set.seed(123)
porcentaje<-0.11
corte <- sample(nrow(datos),nrow(datos)*porcentaje)
train <- datos[corte, ]

max(train[ ,2:ncol(train)]) # max pixel value is 255, lets use this to scale data
train[ , 2:ncol(train)] <- train[ , 2:ncol(train)]/255

test<-datos[-corte,]
test[ , 2:ncol(test)] <- test[ , 2:ncol(test)]/255

```


```{r Distribucion digitos, echo = FALSE}
plot1 <- ggplot(datos, aes(x = label, y = (..count..)/sum(..count..))) + geom_bar() + theme_light() +
                labs(y = "Relative frequency", title = "datos dataset") + 
                scale_y_continuous(labels=scales::percent, limits = c(0 , 0.15)) +
                geom_text(stat = "count", 
                          aes(label = scales:: percent((..count..)/sum(..count..)), vjust = -1))

plot2 <- ggplot(train, aes(x = label, y = (..count..)/sum(..count..))) + geom_bar() + theme_light() +
                labs(y = "Relative frequency", title = "train dataset") + 
                scale_y_continuous(labels=scales::percent, limits = c(0 , 0.15)) +
                geom_text(stat = "count", 
                          aes(label = scales:: percent((..count..)/sum(..count..)), vjust = -1))

plot3 <- ggplot(test, aes(x = label, y = (..count..)/sum(..count..))) + geom_bar() + theme_light() +
                labs(y = "Relative frequency", title = "test dataset") + 
                scale_y_continuous(labels=scales::percent, limits = c(0 , 0.15)) +
                geom_text(stat = "count", 
                          aes(label = scales:: percent((..count..)/sum(..count..)), vjust = -1))

grid.arrange(plot1, plot2, plot3, nrow = 3)
```
Se observa una frecuencia constante en la distribucion de los digitos en los datasets. 

```{r Linear Kernel, echo = FALSE}
model1_linear <- ksvm(label ~ ., data = train, scaled = FALSE, kernel = "vanilladot", C = 1)
print(model1_linear) 

eval1_linear <- predict(model1_linear, newdata = test, type = "response")
confusionMatrix(eval1_linear, test$label)  


model2_linear <- ksvm(label ~ ., data = train, scaled = FALSE, kernel = "vanilladot", C = 10)
print(model2_linear) 

eval2_linear <- predict(model2_linear, newdata = test, type = "response")
confusionMatrix(eval2_linear, test$label) 


grid_linear <- expand.grid(C= c(0.001, 0.1 ,1 ,10 ,100)) # defining range of C

fit.linear <- train(label ~ ., data = train, metric = "Accuracy", method = "svmLinear",
                    tuneGrid = grid_linear, preProcess = NULL,
                    trControl = trainControl(method = "cv", number = 5))

# printing results of 5 cross validation
print(fit.linear) 
plot(fit.linear)

```
Support Vector Machines es un algoritmo de deep learning que es efectivo en espacios de altas dimensiones. Los subsets generados durante el proceso son los vectores de soporte que hacen que el uso de memoria sea mas efectivo. La eficacia del algoritmo segun la matriz de confusion fue de un 90.92% 
En el codigo se utlizaron bloques de: https://github.com/Srungeer-Simha/MNIST-digit-recognition-using-SVM/blob/master/MNIST%20digit%20recognition%20-%20SVM.R 

Entre los tres algoritmos, para la prediccion de manuscritos, se usara la red neuronal simple. Este con la CNN tuvieron un accuracy similar, cabe pensar que esto es por la simplicidad de imagenes entonces los filtros de la CNN no pudieron ayudar mucho para hacer más simple la imagén por lo que el performance es igual al de la red neuronal simple.

##Prediccion con manuscritos de los participantes del grupo

Para esto primero se debera de cargar las imagenes a R, se uso  el paquete EBImage, instalado con BiocManager. Aqui se puede encontrar la documentacion
http://www.bioconductor.org/packages/release/bioc/vignettes/EBImage/inst/doc/EBImage-introduction.html#3_Image_data_representation , se muestra la imagen cargada, se cambia a una escala de grises, se convierte en un array y luego se convierte en un vector de 784 datos que corresponde a los pixeles.

Se hace un dataframe completo con todos los manuscritos a usar y se aplica el modelo de prediccion, asimismo se mostraran cada imagen hecha por los integrantes del grupo. 

```{r echo=FALSE}
library("EBImage")
a <- readImage("./no4luispedro.png")
a = resize(a, w=28, h=28)
display(a, method = "raster")
str(a)
a<-channel(a,"gray")
a
a <- as.array(a)
a <-as.vector(a)

b <- readImage("./no7luispedro.png")
b = resize(b, w=28, h=28)
display(b, method = "raster")
str(b)
b<-channel(b,"gray")
b
b <- as.array(b)
b <-as.vector(b)

c <- readImage("./no9luispedro.png")
c = resize(c, w=28, h=28)
display(c, method = "raster")
str(c)
c<-channel(c,"gray")
c
c <- as.array(c)
c <-as.vector(c)

x <- readImage("./unoMarisa.png")
x = resize(x, w=28, h=28)
display(x, method = "raster")
str(x)
x<-channel(x,"gray")
x
x <- as.array(x)
x <-as.vector(x)

y <- readImage("./tresMarisa.png")
y = resize(y, w=28, h=28)
display(y, method = "raster")
y<-channel(y,"gray")
y
y <- as.array(y)
y <-as.vector(y)

z <- readImage("./cincoMarisa.png")
z = resize(z, w=28, h=28)
display(z, method = "raster")
z<-channel(z,"gray")
z
z <- as.array(z)
z <-as.vector(z)

numbers<- data.frame(a,b, c, x,y,z)
numbers <- t(numbers)
numbers <- as.data.frame(numbers)

par(mfrow=c(2,3))
lapply(1:3, 
    function(x) image(
                    rotate(matrix(unlist(numbers[x,-1]),nrow = 28,byrow = T)),
                    col=grey.colors(255),
                    xlab=numbers[x,1]
                )
)
par(mfrow=c(1,1)) # set plot options back to default

num<-0:783
nums=sprintf("pixel%d",num)
colnames(numbers)<-nums
```

Se procede a activar el environment para h2o y a hacer la prediccion. En la prediccion se tendra como resultado un df con image id que se denomida por 1,2..6 y el valor predicho por el modelo en este test. 

```{r echo=FALSE}
 
test = as.h2o(numbers)

h2otest <- h2o.predict(modelNN, test)

testt = as.data.frame(h2otest)
testt = data.frame(ImageId = seq(1,length(testt$predict)), Label = testt$predict)
testt
```

Referencia de codigo realizar el modelo
http://didericksen.github.io/deeplearning-r-h2o/

```{r shutdown java envvvv, echo=FALSE}
h2o.shutdown(prompt = F)

```

Se puede ver que en el dataframe de resultado de prediccion image ids. estos corresponden a las imagenes cargadas. 
La image id 1 es el numero 4, image id 2 es 7, image id 3 es 9, image id 4 es 1, image id 5 es 3 e image id 6 es 5.Podemos ver que se equivoco en la prediccion de la id 2, 3 y 4, teniendo un accuracy del 50%. 

Esto puede deberse a que los dibujos pueden parecerse a otros numeros usados en el conjunto de train. Confundio un 7 por 2, un 9 por 4 y un 1 por 2. Esto puede ser porque los pinceles usados también al ser muy gruesos pueden confundir al algoritmo en la prediccion de las imagenes subidas por los integrantes. 







